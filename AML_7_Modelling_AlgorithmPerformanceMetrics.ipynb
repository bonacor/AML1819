{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Algorithm Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how to select and use different ML performance metrics in Python with *scikit-learn*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see various algorithm evaluation metrics and we will demonstrate them for both classification and regression type ML problems. \n",
    "\n",
    "In this section we need to focus on how to evaluate and compare algos themselves, so we need more models, and to do so we need more input datasets:\n",
    "\n",
    "* For CLASSIFICATION metrics, the Pima Indians onset of diabetes dataset is used as demonstration. This is a binary classification problem where all of the input variables are numeric.\n",
    "\n",
    "* For REGRESSION metrics, we introduce the Boston House Price dataset and we use it as demonstration. This is a regression problem where all of the input variables are also numeric.\n",
    "\n",
    "All recipes evaluate the same algorithms, ***Logistic Regression*** for classification and ***Linear Regression*** for the regression problems. A 10-fold CV test harness is used to demonstrate each metric.\n",
    "\n",
    "More about ML algorithm performance metrics supported by scikit-learn can be found [here](http://scikit-learn.org/stable/modules/model_evaluation.html) on the page \"Model evaluation: quantifying the quality of predictions\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CAVEAT. A caveat in these recipes is the `cross validation.cross_val_score` function (more [here](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_ score.html)) used to report the performance in each recipe. It does allow the use of different scoring metrics that will be discussed, but all scores are reported so that they can be sorted in ascending order (largest score is best). Some evaluation metrics (like mean squared error) are naturally descending scores (the smallest score is best) and as such are reported as negative by the cross validation.cross val score() function. This is important to note, because some scores will be reported as negative that by definition can never be negative.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will review how to use the following metrics:\n",
    "\n",
    "* [CLAS-1] Classification Accuracy\n",
    "* [CLAS-2] Logarithmic Loss\n",
    "* [CLAS-3] Area Under ROC Curve\n",
    "* [CLAS-4] Confusion Matrix\n",
    "* [CLAS-5] Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CLAS-1] Classification Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy is **the number of correct predictions made as a ratio of all predictions made**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770 (0.048)\n"
     ]
    }
   ],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Cross Validation Classification Accuracy\n",
    "scoring = 'accuracy'                                             # <--- \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CLAS-2] Logarithmic Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logarithmic loss (or logloss) is **a performance metric for evaluating the predictions of probabilities of membership to a given class**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: -0.493 (0.047)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification LogLoss\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller logloss is better with 0 representing a perfect logloss. As mentioned above, the\n",
    "measure is inverted to be ascending when using the `cross_val_score()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CLAS-3] Area Under ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under ROC (Receiver Operating Characteristic) Curve (or AUC for short) is **a performance metric for binary classification problems**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification ROC AUC\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CLAS-4] Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is **a handy presentation of the accuracy of a model with two or more classes**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix              # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  21]\n",
      " [ 41  51]]\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.33\n",
    "seed = 7\n",
    "\n",
    "# Cross Validation Classification Confusion Matrix\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "    random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)              # <---\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the array is printed without headings, you can see that the majority of the predictions fall on the diagonal line of the matrix (which are correct predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CLAS-5] Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also **a convenience report provided by the scikit-learn library** in case of classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report               # <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.87      0.82       162\n",
      "        1.0       0.71      0.55      0.62        92\n",
      "\n",
      "avg / total       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.33\n",
    "seed = 7\n",
    "\n",
    "# Cross Validation Classification Report\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "    random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)               # <---\n",
    "print(report)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will review 3 of the most common metrics for evaluating predictions on regression ML problems:\n",
    "* [REGR-1] Mean Absolute Error\n",
    "* [REGR-2] Mean Squared Error\n",
    "* [REGR-3] $R^2$\n",
    "\n",
    "In the regression examples, we will use the Boston house price dataset, which you can find (and should dowload from) here:\n",
    "* https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [REGR-1] Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Absolute Error (or MAE) is **the sum of the absolute differences between predictions and actual values**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input data\n",
    "filename = 'housing.data.csv'\n",
    "names=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -4.005 (2.084)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MAE\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'                                  # <---\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MAE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [REGR-2] Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Squared Error (or MSE) is much like the MAE in that **it provides a gross idea of the magnitude of error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -34.705 (45.574)\n"
     ]
    }
   ],
   "source": [
    "#num_folds = 10       # a remnant..\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MSE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [REGR-3] $R^2$ metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R^2$ (or R Squared) metric provides **an indication of the goodness of fit of a set of predictions to the actual values**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.203 (0.595)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression R^2\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'                                                     # <---\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"R^2: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did:\n",
    "\n",
    "* we showe metrics  you can use to evaluate your ML algorithms. We showed how to implement in scikitlearn the use of  3 classification metrics (Accuracy, LogLoss and AUC) and 2 convenience methods for classification prediction results (Confusion Matrix and Classification Report), as well as 3 metrics for regression problems (MAE, MSE, R2). There are more, of course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how to evaluate the performance of ML algorithms using various metrics. We know how to use those metrics to estimate the performance of algorithms on new unseen data using resampling. It is time to start looking at ML algorithms themselves. Starting with CLASSIFICATION techniques.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
